#!/bin/bash
# =========================================
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# backend(FastAPI) ã¨ frontend(React) ã‚’åŒæ™‚èµ·å‹•
# =========================================

# ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«çµ‚äº†
set -e

# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸
cd "$(dirname "$0")"

echo "ğŸ”§ Backend ã¨ Frontend ã‚’åŒæ™‚ã«èµ·å‹•ã—ã¾ã™..."
echo "---------------------------------------------"

# Python ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–ï¼ˆå¿…è¦ãªã‚‰ï¼‰
# source ~/.venv/bin/activate

# backend èµ·å‹•
echo "ğŸš€ Backend ã‚’èµ·å‹•ä¸­..."
cd backend
#!/usr/bin/env bash
set -euo pipefail

# ==== è¨­å®š ====
PORT=8000
OLLAMA_MODEL=${OLLAMA_MODEL:-mistral}
USE_OLLAMA=1

echo "==> Ollamaã‚µãƒ¼ãƒã®ç¢ºèª..."
if ! curl -s http://localhost:11434/api/version >/dev/null; then
  echo "âš ï¸ OllamaãŒå‹•ã„ã¦ã„ã¾ã›ã‚“ã€‚èµ·å‹•ã—ã¾ã™..."
  if command -v brew >/dev/null 2>&1; then
    brew services start ollama
    sleep 3
  else
    echo "brewãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ‰‹å‹•ã§ 'ollama serve' ã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚"
  fi
else
  echo "âœ… Ollamaã‚µãƒ¼ãƒã¯ç¨¼åƒä¸­ã§ã™ã€‚"
fi

echo "==> FastAPIã‚µãƒ¼ãƒã‚’èµ·å‹•..."
export USE_OLLAMA=$USE_OLLAMA
export OLLAMA_MODEL=$OLLAMA_MODEL

# ä»®æƒ³ç’°å¢ƒãŒã‚ã‚Œã°æœ‰åŠ¹åŒ–
if [ -d ".venv" ]; then
  source .venv/bin/activate
fi

# Uvicornèµ·å‹•
uvicorn main:app --reload --port $PORT
cd ..

# frontend èµ·å‹•
echo "ğŸ’» Frontend ã‚’èµ·å‹•ä¸­..."
cd frontend
npm install
npm run dev &
FRONTEND_PID=$!
cd ..

# ä¸¡æ–¹ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç›£è¦–
echo "---------------------------------------------"
echo "âœ… Backend(PID=$BACKEND_PID) ã¨ Frontend(PID=$FRONTEND_PID) ãŒèµ·å‹•ã—ã¾ã—ãŸã€‚"
echo "ğŸŒ Backend: http://localhost:8000"
echo "ğŸŒ Frontend: http://localhost:5173"
echo "çµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚"
echo "---------------------------------------------"

# Ctrl+C ã§ä¸¡æ–¹åœæ­¢
trap "echo 'ğŸ›‘ åœæ­¢ä¸­...'; kill $BACKEND_PID $FRONTEND_PID" SIGINT

# ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¾…æ©Ÿ
wait

