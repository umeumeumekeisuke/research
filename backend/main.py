from fastapi import FastAPI, Query
from pydantic import BaseModel
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
import logging, os, re, json, requests, glob
from typing import List, Dict, Any
from fastapi.middleware.cors import CORSMiddleware

# httpxï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã‚‚å‹•ããƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
try:
    import httpx
except ImportError:
    httpx = None

# ===== åŸºæœ¬è¨­å®š =====
logging.basicConfig(level=logging.INFO)
app = FastAPI()
JST = ZoneInfo("Asia/Tokyo")

# ===== ChatGPT (OpenAI API) è¨­å®š =====
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL   = os.getenv("OPENAI_MODEL", "gpt-5-nano")

# ===== ãƒ¢ãƒ‡ãƒ«å®šç¾© =====
class ChatRequest(BaseModel):
    content: str
    category: str
    type: str = "text"

class ChatResponse(BaseModel):
    content: str
    sender: str = "bot"
    timestamp: str
    category: str

# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
def parse_date(text: str) -> str:
    dt = datetime.now(JST)
    if "æ˜å¾Œæ—¥" in text: dt += timedelta(days=2)
    elif "æ˜æ—¥" in text: dt += timedelta(days=1)
    elif re.search(r"(ä»Šæ—¥|æœ¬æ—¥|ãã‚‡ã†)", text): pass
    else:
        m = re.search(r"(\d{4})[-/\.](\d{1,2})[-/\.](\d{1,2})", text)
        if m:
            y, mo, d = map(int, m.groups())
            return datetime(y, mo, d, tzinfo=JST).date().isoformat()
    return dt.date().isoformat()

def stringify(val: Any) -> str:
    try:
        if isinstance(val, (dict, list)):
            return json.dumps(val, ensure_ascii=False)
        return str(val)
    except Exception:
        return str(val)

# ===== ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆ./data/*.jsonï¼‰=====
def load_all_jsons(data_dir: str = "./data") -> Dict[str, Any]:
    store: Dict[str, Any] = {}
    for path in glob.glob(os.path.join(data_dir, "*.json")):
        name = os.path.splitext(os.path.basename(path))[0]
        try:
            with open(path, "r", encoding="utf-8") as f:
                store[name] = json.load(f)
        except Exception as e:
            logging.warning(f"Failed to load {path}: {e}")
    return store

DATA = load_all_jsons()
CAL = DATA.get("academic_calendar", {"events": []})

# ---- æ•™å“¡: facultyå½¢å¼ or æ—¥æœ¬èªé…åˆ—ã®ä¸¡å¯¾å¿œï¼ˆåå‰/æ‰€å±/memo ã«æ­£è¦åŒ–ï¼‰----
_raw_teachers = DATA.get("ryukyu_office_hours", [])
TEACHERS: List[dict] = []
if isinstance(_raw_teachers, list):
    TEACHERS = _raw_teachers
elif isinstance(_raw_teachers, dict) and isinstance(_raw_teachers.get("faculty"), list):
    for fac in _raw_teachers["faculty"]:
        name = fac.get("name_ja") or fac.get("name") or fac.get("name_en") or ""
        dept = fac.get("department") or ""
        ohs = fac.get("office_hours", [])
        if isinstance(ohs, list) and ohs:
            memo = " / ".join(
                f"{o.get('weekday','')} {o.get('start','')}-{o.get('end','')}"
                for o in ohs
            )
        else:
            memo = fac.get("memo", "ï¼ˆæƒ…å ±ãªã—ï¼‰")
        TEACHERS.append({"åå‰": name, "æ‰€å±": dept, "memo": memo})

CLUBS: List[dict] = DATA.get("clubs", []) or []

# ===== ChatGPTãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
def call_openai(messages: List[Dict[str, str]], timeout: int = 12) -> str:
    """OpenAI Responses APIã‚’å©ã„ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ï¼ˆhttpxãŒç„¡ã‘ã‚Œã°requestsï¼‰"""
    if not OPENAI_API_KEY:
        return ""
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    payload = {"model": OPENAI_MODEL, "input": messages, "store": False}
    url = "https://api.openai.com/v1/responses"
    try:
        if httpx is not None:
            with httpx.Client(timeout=timeout) as client:
                r = client.post(url, headers=headers, json=payload)
                r.raise_for_status()
                data = r.json()
        else:
            r = requests.post(url, headers=headers, json=payload, timeout=timeout)
            r.raise_for_status()
            data = r.json()

        for item in data.get("output", []):
            if item.get("type") == "message":
                cont = item.get("content") or []
                if cont and isinstance(cont, list):
                    first = cont[0]
                    if first.get("type") == "output_text":
                        return (first.get("text") or "").strip()
            if item.get("type") == "output_text":
                return (item.get("text") or "").strip()
        return (data.get("text") or "").strip()
    except Exception as e:
        logging.warning(f"OpenAI error: {e}")
        return ""

# ===== ãƒ„ãƒ¼ãƒ«åˆ†é¡ =====
def classify_tool(user_text: str) -> str:
    # ã¾ãšã¯OpenAIã§åˆ†é¡ï¼ˆã‚ã‚Œã°ï¼‰
    if OPENAI_API_KEY:
        sys = (
            "ã‚ãªãŸã¯å¤§å­¦ã«é–¢ã™ã‚‹è³ªå•ã‚’åˆ†é¡ã—ã¾ã™ã€‚"
            "å¿…ãšJSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"
            ' å‡ºåŠ›ä¾‹: {"tool":"teacher"}'
            ' å€™è£œ: ["calendar","teacher","clubs","weather","data_qa","other"]'
        )
        out = call_openai(
            [{"role": "system", "content": sys},
             {"role": "user", "content": user_text}],
            timeout=8,
        )
        if out:
            try:
                tool = json.loads(out).get("tool")
                if tool in {"calendar","teacher","clubs","weather","data_qa","other"}:
                    return tool
            except Exception:
                pass

    # ---- æ­£è¦è¡¨ç¾ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆä¼‘æš‡ï¼†æˆæ¥­ãƒ¯ãƒ¼ãƒ‰ã‚’å¼·åŒ–ï¼‰----
    if re.search(r"(å¤ä¼‘ã¿|å†¬ä¼‘ã¿|æ˜¥ä¼‘ã¿|ä¼‘æ¥­|ä¼‘æš‡|ç¥æ—¥|é€£ä¼‘|å­¦äº‹æš¦|ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«)", user_text):
        return "calendar"
    if re.search(r"(æˆæ¥­é–‹å§‹|æˆæ¥­å†é–‹|æˆæ¥­çµ‚äº†|é–‹è¬›|é–‰è¬›|æˆæ¥­|ä¼‘è¬›|è©¦é¨“|æˆç¸¾|å­¦æœŸ|ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼|å­¦å¹´æš¦|Q[1-4ï¼‘-ï¼”])", user_text):
        return "calendar"
    if re.search(r"(å…ˆç”Ÿ|æ•™æˆ|ã‚ªãƒ•ã‚£ã‚¹ã‚¢ãƒ¯ãƒ¼|ç ”ç©¶å®¤)", user_text):
        return "teacher"
    if re.search(r"(ã‚µãƒ¼ã‚¯ãƒ«|éƒ¨æ´»|ã‚¯ãƒ©ãƒ–|åŒå¥½ä¼š|å›£ä½“|éƒ¨å“¡)", user_text):
        return "clubs"
    if "å¤©æ°—" in user_text:
        return "weather"
    return "data_qa"

# ===== ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æ¤œç´¢ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å„ªå…ˆ â†’ æ—¥ä»˜ãƒ’ãƒƒãƒˆï¼‰=====
def find_calendar(text: str) -> str:
    events = CAL.get("events", [])
    if not isinstance(events, list):
        return "å­¦å¹´æš¦ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚"

    # æ­£è¦åŒ–ï¼ˆå…¨è§’æ•°å­—â†’åŠè§’ï¼‰
    z2h = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")
    norm_text = text.translate(z2h)

    def fmt_line(title: str, s: str, ed: str) -> str:
        if s and ed and ed != s:
            return f"- {title}: {s} ï½ {ed}"
        elif s:
            return f"- {title}: {s}"
        return f"- {title}"

    # 1) ä¼‘æš‡ç³»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    kw_map = {
        "å¤": ["å¤å­£ä¼‘æ¥­", "å¤ä¼‘ã¿"],
        "å†¬": ["å†¬å­£ä¼‘æ¥­", "å†¬ä¼‘ã¿"],
        "æ˜¥": ["æ˜¥å­£ä¼‘æ¥­", "æ˜¥ä¼‘ã¿"],
    }
    season = None
    if re.search(r"å¤", norm_text): season = "å¤"
    elif re.search(r"å†¬", norm_text): season = "å†¬"
    elif re.search(r"æ˜¥", norm_text): season = "æ˜¥"

    if season or re.search(r"(ä¼‘æ¥­|ä¼‘æš‡|ä¼‘ã¿)", norm_text):
        keys = kw_map.get(season, None)
        hits = []
        for e in events:
            title = e.get("title", "")
            if (keys and any(k in title for k in keys)) or (not keys and re.search(r"(ä¼‘æ¥­|ä¼‘æš‡|ä¼‘ã¿)", title)):
                s = e.get("date") or e.get("date_start")
                ed = e.get("end")  or e.get("date_end") or s
                hits.append((title, s, ed))
        if hits:
            head = f"ğŸ“… {season+'ä¼‘ã¿' if season else 'ä¼‘æš‡é–¢é€£'}ã‚¤ãƒ™ãƒ³ãƒˆ:"
            return "\n".join([head] + [fmt_line(t, s, ed) for (t, s, ed) in hits])

    # 2) æˆæ¥­é–‹å§‹/çµ‚äº†ãƒ»é–‹è¬›/é–‰è¬› ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
    kw_start = re.search(r"(æˆæ¥­é–‹å§‹|æˆæ¥­å†é–‹|é–‹è¬›)", norm_text)
    kw_end   = re.search(r"(æˆæ¥­çµ‚äº†|é–‰è¬›)", norm_text)

    # å­¦æœŸã‚„ã‚¯ã‚©ãƒ¼ã‚¿ãƒ¼ã®æ¡ä»¶æŠ½å‡º
    want_front = bool(re.search(r"(å‰å­¦æœŸ|å‰æœŸ)", norm_text))
    want_back  = bool(re.search(r"(å¾Œå­¦æœŸ|å¾ŒæœŸ)", norm_text))
    m_q = re.search(r"ç¬¬\s*([1-4])\s*ã‚¯ã‚©ãƒ¼ã‚¿ãƒ¼", norm_text)
    want_q = m_q.group(1) if m_q else None  # "1".."4"

    def match_term_filters(title: str) -> bool:
        # å‰å­¦æœŸâ‡”ç¬¬1/2Qã€å¾Œå­¦æœŸâ‡”ç¬¬3/4Q ã®ã‚†ã‚‹ã„å¯¾å¿œ
        if want_q and (f"ç¬¬{want_q}ã‚¯ã‚©ãƒ¼ã‚¿ãƒ¼" not in title):
            return False
        if want_front and not (("å‰å­¦æœŸ" in title) or ("ç¬¬1ã‚¯ã‚©ãƒ¼ã‚¿ãƒ¼" in title) or ("ç¬¬2ã‚¯ã‚©ãƒ¼ã‚¿ãƒ¼" in title)):
            return False
        if want_back and not (("å¾Œå­¦æœŸ" in title) or ("ç¬¬3ã‚¯ã‚©ãƒ¼ã‚¿ãƒ¼" in title) or ("ç¬¬4ã‚¯ã‚©ãƒ¼ã‚¿ãƒ¼" in title)):
            return False
        return True

    if kw_start or kw_end:
        hits = []
        for e in events:
            title = e.get("title", "")
            if kw_start and re.search(r"(æˆæ¥­é–‹å§‹|æˆæ¥­å†é–‹|é–‹è¬›)", title):
                if match_term_filters(title):
                    s = e.get("date") or e.get("date_start")
                    ed = e.get("end")  or e.get("date_end") or s
                    hits.append((title, s, ed))
            elif kw_end and re.search(r"(æˆæ¥­çµ‚äº†|é–‰è¬›)", title):
                if match_term_filters(title):
                    s = e.get("date") or e.get("date_start")
                    ed = e.get("end")  or e.get("date_end") or s
                    hits.append((title, s, ed))
        if hits:
            head = "ğŸ“… æˆæ¥­ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«:"
            return "\n".join([head] + [fmt_line(t, s, ed) for (t, s, ed) in hits])

    # 3) æ—¥ä»˜ã§ã®ãƒ’ãƒƒãƒˆï¼ˆã€Œä»Šæ—¥/æ˜æ—¥/YYYY-MM-DDã€ãªã©ï¼‰
    target = parse_date(norm_text)
    day_hits = []
    for e in events:
        s = e.get("date") or e.get("date_start")
        ed = e.get("end")  or e.get("date_end") or s
        if s and ed and s <= target <= ed:
            day_hits.append(e.get("title", "(ç„¡é¡Œ)"))
    if not day_hits:
        return f"ğŸ“… {target} ã«è©²å½“ã‚¤ãƒ™ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    return "ğŸ“… " + target + " ã®ä¸»ãªã‚¤ãƒ™ãƒ³ãƒˆ:\n" + "\n".join(f"- {h}" for h in day_hits)

# ===== æ•™å“¡æ¤œç´¢ =====
NAME_JA_RE = re.compile(r"[ä¸€-é¾¥ã€…ã€†ãƒµãƒ¶ã-ã‚“ã‚¡-ãƒ´ãƒ¼A-Za-zãƒ»\s]+")
CUT_TAIL_RE = re.compile(r"(ã®.*|ã«?ã¤ã„ã¦.*|ã£ã¦.*|ã¨ã¯.*|ã¯\??|ã‚’\??|ã«\??|ã§\??|ã€.*|ã€‚.*)$")

def find_teacher(text: str) -> str:
    if not TEACHERS:
        return "æ•™å“¡ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚/admin/debug-data ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

    # æ•¬ç§°é™¤å» â†’ æ–‡æœ«ãƒã‚¤ã‚ºé™¤å» â†’ æ°åæ–­ç‰‡æŠ½å‡º
    t = re.sub(r"(å…ˆç”Ÿ|æ•™æˆ|ã•ã‚“|æ°|æ§˜)", "", text)
    t = CUT_TAIL_RE.sub("", t)
    m = NAME_JA_RE.search(t)
    key = (m.group(0).strip() if m else "")[:20]

    if not key:
        return "å…ˆç”Ÿã®ãŠåå‰ã‚’å«ã‚ã¦èã„ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šäº•ä¸Šå…ˆç”Ÿã®ã‚ªãƒ•ã‚£ã‚¹ã‚¢ãƒ¯ãƒ¼ã¯ï¼Ÿï¼‰ã€‚"

    # å®Œå…¨ä¸€è‡´å„ªå…ˆ â†’ éƒ¨åˆ†ä¸€è‡´
    matches = [x for x in TEACHERS if x.get("åå‰") and x["åå‰"] in text]
    if not matches:
        matches = [x for x in TEACHERS if key in (x.get("åå‰") or "")]

    if not matches:
        # å€™è£œãƒˆãƒƒãƒ—5ï¼ˆé ­æ–‡å­—ã–ã£ãã‚Šï¼‰
        cands = [x.get("åå‰") for x in TEACHERS if key and key[0] in (x.get("åå‰") or "")]
        cands = [c for c in cands if c]
        seen, top = set(), []
        for c in cands:
            if c not in seen:
                seen.add(c); top.append(c)
            if len(top) >= 5: break
        if top:
            return f"ã€Œ{key}ã€ã«ä¸€è‡´ã™ã‚‹å…ˆç”Ÿã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\nå€™è£œ: " + " / ".join(top)
        return f"ã€Œ{key}ã€ã«ä¸€è‡´ã™ã‚‹å…ˆç”Ÿã®æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

    if len(matches) == 1:
        t = matches[0]
        return f"{t.get('æ‰€å±','')}ã®{t.get('åå‰','')}å…ˆç”Ÿã®ã‚ªãƒ•ã‚£ã‚¹ã‚¢ãƒ¯ãƒ¼ï¼š{t.get('memo','æƒ…å ±ãªã—')}"

    lines = ["è¤‡æ•°ã®å…ˆç”ŸãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼š"]
    for t in matches[:20]:
        lines.append(f"- {t.get('æ‰€å±','')} {t.get('åå‰','')}ï¼š{t.get('memo','æƒ…å ±ãªã—')}")
    if len(matches) > 20:
        lines.append(f"...ã»ã‹ {len(matches)-20} ä»¶")
    return "\n".join(lines)

# ===== ã‚µãƒ¼ã‚¯ãƒ«æ¤œç´¢ï¼ˆå¼·åŒ–ç‰ˆï¼‰=====
_CLUB_STOPWORDS = re.compile(r"(ç‰çƒå¤§å­¦|ç‰å¤§|å¤§å­¦|å…¨å­¦|éƒ¨|ã‚¯ãƒ©ãƒ–|ã‚µãƒ¼ã‚¯ãƒ«|åŒå¥½ä¼š|ãƒãƒ¼ãƒ |éƒ¨æ´»|ãƒ»|ï¼|-|ãƒ¼|ï¼¿|â€|â€”|â€•|\s+)")

def _norm_club(s: str) -> str:
    s = s or ""
    s = s.lower()
    s = _CLUB_STOPWORDS.sub("", s)
    return s

def _tokenize(s: str) -> List[str]:
    return [w for w in re.findall(r"[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ´ãƒ¼a-z0-9]+", s.lower()) if w]

# ç¨®ç›®â†’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µï¼‰
SPORT_KEYWORDS = {
    "ã‚µãƒƒã‚«ãƒ¼": ["ã‚µãƒƒã‚«ãƒ¼", "soccer", "ãƒ•ãƒƒãƒˆãƒœãƒ¼ãƒ«", "ãƒ•ãƒƒãƒˆã‚µãƒ«"],
    "ãƒ†ãƒ‹ã‚¹": ["ãƒ†ãƒ‹ã‚¹", "tennis", "åº­çƒ"],
    "ãƒã‚¹ã‚±": ["ãƒã‚¹ã‚±", "ãƒã‚¹ã‚±ãƒƒãƒˆ", "basketball", "3Ã—3", "3x3"],
    "ãƒãƒ¬ãƒ¼": ["ãƒãƒ¬ãƒ¼", "ãƒãƒ¬ãƒ¼ãƒœãƒ¼ãƒ«", "volleyball"],
    "é‡çƒ": ["é‡çƒ", "ãƒ™ãƒ¼ã‚¹ãƒœãƒ¼ãƒ«", "baseball"],
    "ãƒ©ã‚°ãƒ“ãƒ¼": ["ãƒ©ã‚°ãƒ“ãƒ¼", "rugby"],
}

def find_club(text: str) -> str:
    """
    è‡ªç„¶æ–‡ã«å¯¾å¿œã—ãŸã‚µãƒ¼ã‚¯ãƒ«/éƒ¨æ´»æ¤œç´¢ã€‚
    - æ›–æ˜§ä¸€è‡´ï¼ˆåç§°ã®æ­£è¦åŒ– & ãƒˆãƒ¼ã‚¯ãƒ³ç…§åˆï¼‰
    - ç¨®ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¾‹: ã‚µãƒƒã‚«ãƒ¼â†’ã‚µãƒƒã‚«ãƒ¼/ãƒ•ãƒƒãƒˆã‚µãƒ«/ãƒ•ãƒƒãƒˆãƒœãƒ¼ãƒ«ï¼‰
    - ä¸€è¦§è³ªå•ï¼ˆã©ã‚“ãªéƒ¨æ´»/ã‚µãƒ¼ã‚¯ãƒ«ãŒã‚ã‚‹ï¼Ÿï¼‰ã«ç°¡æ˜“å¯¾å¿œ
    """
    if not CLUBS:
        return "ã‚µãƒ¼ã‚¯ãƒ«ãƒ»éƒ¨æ´»ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

    q_raw = text
    q = q_raw.lower()
    q_norm = _norm_club(q_raw)
    q_tokens = _tokenize(q_raw)

    # ä¸€è¦§ç³»ã®è³ªå•
    if re.search(r"(ã©ã‚“ãª|ä¸€è¦§|å…¨éƒ¨|å…¨ã¦|ãªã«ãŒ|ä½•ãŒ).*(éƒ¨|ã‚¯ãƒ©ãƒ–|ã‚µãƒ¼ã‚¯ãƒ«)", q) or q.strip() in {"éƒ¨æ´»","ã‚µãƒ¼ã‚¯ãƒ«","ã‚¯ãƒ©ãƒ–"}:
        names = [c.get("name") for c in CLUBS if c.get("name")]
        if not names:
            return "ã‚µãƒ¼ã‚¯ãƒ«æƒ…å ±ãŒç©ºã®ã‚ˆã†ã§ã™ã€‚"
        head = f"ğŸ· ã‚µãƒ¼ã‚¯ãƒ«/éƒ¨æ´»ã®ä¾‹ï¼ˆ{min(len(names), 20)}ä»¶è¡¨ç¤º / å…¨{len(names)}ä»¶ï¼‰:"
        return "\n".join([head] + [f"- {n}" for n in names[:20]])

    # ç¨®ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆä¾‹: ã‚µãƒƒã‚«ãƒ¼éƒ¨ã‚ã‚‹ï¼Ÿ â†’ ã‚µãƒƒã‚«ãƒ¼ç¾¤ã‚’æ¤œç´¢ï¼‰
    wanted_keywords = set()
    for group, kws in SPORT_KEYWORDS.items():
        if any(k.lower() in q for k in kws):
            wanted_keywords.update([k.lower() for k in kws])

    def score_item(it: dict) -> int:
        s = 0
        name = it.get("name") or ""
        detail = it.get("detail") or ""
        location = it.get("location") or ""
        day = it.get("day") or ""
        blob = (name + " " + detail + " " + location + " " + day).lower()

        # 1) æ­£è¦åŒ–åç§°ã®ç›¸äº’åŒ…å«ï¼ˆå¼·ï¼‰
        nn = _norm_club(name)
        if nn and (nn in q_norm or q_norm in nn):
            s += 8

        # 2) ãƒˆãƒ¼ã‚¯ãƒ³ä¸€è‡´ï¼ˆä¸­ï¼‰
        s += sum(1 for t in q_tokens if t and t in blob)

        # 3) ç¨®ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¼·ï¼‰
        if wanted_keywords:
            s += sum(2 for wk in wanted_keywords if wk in blob)

        # 4) ã‚¯ã‚¨ãƒªãŒçŸ­ã„æ™‚ã®æ•‘æ¸ˆï¼šä»£è¡¨èªï¼ˆéƒ¨/ã‚¯ãƒ©ãƒ–/ã‚µãƒ¼ã‚¯ãƒ«ï¼‰ã ã‘ãªã‚‰åå‰ãƒ’ãƒ³ãƒˆ
        if not q_tokens and ("éƒ¨" in q or "ã‚¯ãƒ©ãƒ–" in q or "ã‚µãƒ¼ã‚¯ãƒ«" in q):
            if "éƒ¨" in name or "ã‚¯ãƒ©ãƒ–" in name or "ã‚µãƒ¼ã‚¯ãƒ«" in name:
                s += 1

        return s

    scored = [(score_item(it), it) for it in CLUBS]
    scored = [x for x in scored if x[0] > 0]
    scored.sort(key=lambda x: x[0], reverse=True)

    if not scored:
        return "è©²å½“ã™ã‚‹ã‚µãƒ¼ã‚¯ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

    # ä¸Šä½ã‚’è¿”ã™ï¼ˆæœ€å¤§3ä»¶ï¼‰
    top = [it for (_, it) in scored[:3]]

    def fmt(c: dict) -> str:
        return (
            f"ğŸ· {c.get('name','(åç§°ä¸æ˜)')}\n"
            f"- æ´»å‹•æ—¥: {c.get('day','æœªè¨˜è¼‰')}\n"
            f"- å ´æ‰€: {c.get('location','æœªè¨˜è¼‰')}\n"
            f"{('- æ¦‚è¦: ' + c['detail']) if c.get('detail') else ''}"
            f"{('\n- SNS: ' + c['sns']) if c.get('sns') else ''}"
        ).rstrip()

    if len(scored) > 3:
        alt_names = [it.get("name") for (_, it) in scored[3:8] if it.get("name")]
        alt_line = "\nã»ã‹ã®å€™è£œ: " + " / ".join(alt_names) if alt_names else ""
    else:
        alt_line = ""

    return "\n\n".join([fmt(c) for c in top]) + alt_line

# ===== å¤©æ°— =====
def get_weather(text: str) -> str:
    try:
        loc = "é‚£è¦‡"
        m = re.search(r"(æœ­å¹Œ|ä»™å°|æ±äº¬|æ¨ªæµœ|åå¤å±‹|äº¬éƒ½|å¤§é˜ª|ç¥æˆ¸|åºƒå³¶|ç¦å²¡|é‚£è¦‡|æ²–ç¸„)", text)
        if m: loc = m.group(1)
        g = requests.get(
            "https://geocoding-api.open-meteo.com/v1/search",
            params={"name": loc, "count": 1, "language": "ja"},
            timeout=6,
        ).json()
        if not g.get("results"):
            return f"{loc} ã®å¤©æ°—æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        lat, lon = g["results"][0]["latitude"], g["results"][0]["longitude"]
        f = requests.get(
            "https://api.open-meteo.com/v1/forecast",
            params={"latitude": lat, "longitude": lon, "current": "temperature_2m,weathercode"},
            timeout=6,
        ).json()
        cur = f.get("current", {})
        t = cur.get("temperature_2m")
        if t is None:
            return f"{loc} ã®ç¾åœ¨æ°—æ¸©ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        return f"{loc} ã®ç¾åœ¨ã®æ°—æ¸©ã¯ {t}â„ƒ ã§ã™ã€‚"
    except Exception as e:
        return f"å¤©æ°—æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼š{e}"

# ===== ãƒ­ãƒ¼ã‚«ãƒ«å…¨æ–‡æ¤œç´¢ =====
def search_data_any(user_text: str, topk=5) -> str:
    terms = [t for t in re.split(r"[^\wä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³ãƒ¼]+", user_text) if t]
    hits = []
    for fname, content in DATA.items():
        if isinstance(content, list):
            for idx, item in enumerate(content):
                blob = stringify(item)
                score = sum(1 for t in terms if t in blob)
                if score:
                    hits.append((score, fname, idx, item))
        elif isinstance(content, dict):
            blob = stringify(content)
            score = sum(1 for t in terms if t in blob)
            if score:
                hits.append((score, fname, "", content))
    hits.sort(key=lambda x: x[0], reverse=True)
    if not hits:
        return "è©²å½“ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    out = ["ğŸ” æ¤œç´¢çµæœ:"]
    for sc, fn, idx, item in hits[:topk]:
        out.append(f"- {fn}[{idx}] ({sc}): {stringify(item)[:300]}")
    return "\n".join(out)

# ===== APIãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° =====
@app.post("/api/chat", response_model=ChatResponse)
def chat(req: ChatRequest):
    text = req.content.strip()
    # ãƒ•ãƒ­ãƒ³ãƒˆæŒ‡å®šã‚«ãƒ†ã‚´ãƒªã‚’å„ªå…ˆ
    valid = {"calendar","teacher","clubs","weather","data_qa","other"}
    tool = req.category if req.category in valid else classify_tool(text)

    if tool == "calendar":
        reply = find_calendar(text)
    elif tool == "teacher":
        reply = find_teacher(text)
    elif tool == "clubs":
        reply = find_club(text)
    elif tool == "weather":
        reply = get_weather(text)
    else:
        out = call_openai(
            [{"role": "system", "content": "ã‚ãªãŸã¯å¤§å­¦ã®è‡ªå‹•å¿œç­”ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
             {"role": "user", "content": text}]
        )
        reply = out or search_data_any(text)
    return ChatResponse(content=reply, timestamp=datetime.now(JST).isoformat(), category=req.category)

# ===== ç®¡ç†ç³»ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ =====
@app.get("/admin/debug-data")
def debug_data():
    return {
        "cwd": os.getcwd(),
        "loaded_keys": list(DATA.keys()),
        "teachers_count": len(TEACHERS),
        "clubs_count": len(CLUBS),
        "calendar_events": len(CAL.get("events", []))
    }

@app.get("/admin/teachers")
def admin_teachers(like: str = Query("", description="éƒ¨åˆ†ä¸€è‡´ã™ã‚‹æ°åã‚’æ¤œç´¢")):
    if not TEACHERS:
        return {"count": 0, "samples": []}
    if not like:
        # å…ˆé ­20ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«åã‚’è¿”ã™
        return {"count": len(TEACHERS), "samples": [t.get("åå‰") for t in TEACHERS[:20]]}
    hits = [t for t in TEACHERS if like in (t.get("åå‰") or "")]
    return {
        "like": like,
        "count": len(hits),
        "names": [t.get("åå‰") for t in hits[:50]],
    }

@app.get("/healthz")
def health():
    return {"status": "ok"}

# ===== CORS =====
app.add_middleware(
    CORSMiddleware,
    allow_origin_regex=r"^https?://(localhost|127\.0\.0\.1):\d+$",
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)